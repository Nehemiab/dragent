from typing import Annotated, Sequence, TypedDict, Literal, Tuple
import operator
import asyncio
import functools
import json
from datetime import datetime
from typing_extensions import NotRequired


from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.tools import tool
from langgraph.graph import END, START, StateGraph
from langgraph.prebuilt import ToolNode   # å®˜æ–¹é¢„ç½®å·¥å…·èŠ‚ç‚¹
from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver #æ£€æŸ¥ç‚¹
from openai import api_key, base_url

from dragent_tools.data_reader import typhoon_api as _real_typhoon_api

# å‡è®¾çš„ LLM å®¢æˆ·ç«¯
import llm.Client as Client
llm = Client.LLMClient()
Expert_llm=Client.LLMClient(api_key="token-abc123",base_url="http://localhost:8888/v1",model="lora1")
# -------------------------------------------------
# 1. çŠ¶æ€å®šä¹‰
# -------------------------------------------------
class TyphoonAlertState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], operator.add]
    # ç”¨äºè®°å½•æœ€åä¸€æ¬¡æ˜¯è°è°ƒç”¨äº†å·¥å…·ï¼Œæ–¹ä¾¿ router è¿”å›
    sender: str
    # å«æ˜Ÿå›¾åªç»™ flood èŠ‚ç‚¹ç”¨ï¼Œä¸è¿›å…¥ messages
    image: NotRequired[bytes]   # æ–°å¢ï¼šå…è®¸ç¼ºå¤±


# -------------------------------------------------
# 2. å·¥å…·å®šä¹‰
# -------------------------------------------------
@tool
def typhoon_api(
    lat: Annotated[float, "çº¬åº¦ï¼Œä¿ç•™ä¸€ä½å°æ•°"],
    lon: Annotated[float, "ç»åº¦ï¼Œä¿ç•™ä¸€ä½å°æ•°"]
) -> dict:
    """æ ¹æ®ç»çº¬åº¦è·å–å°é£å®æ—¶æ•°æ®"""
    # ç»„è£…æˆåŸæ¥å‡½æ•°è®¤è¯†çš„ JSON æ ¼å¼
    payload = json.dumps({
        "name": "typhoon_api",
        "arguments": {
            "latitude": lat,
            "longitude": lon,
            "time": datetime.utcnow().strftime('%Y-%m-%d %H:%M')
        }
    })
    result = _real_typhoon_api(payload)
    print(f"[DEBUG] typhoon_api è¿”å›ï¼š{result}")  # æ‰“å°è¿”å›å€¼
    return result


# æŠŠå·¥å…·ç»Ÿä¸€æ”¾åˆ° ToolNode
tool_node = ToolNode([typhoon_api])


def _make_image_message(image_bytes: bytes) -> HumanMessage:
    # è¿™é‡Œå‡è®¾ä¼ è¿›æ¥çš„æ˜¯ PNG/JPG åŸå§‹å­—èŠ‚
    import base64
    b64 = base64.b64encode(image_bytes).decode()
    # å¦‚æœå›¾ç‰‡å¾ˆå¤§ï¼Œå¯ä»¥æ”¹æˆ `data:image/jpeg;base64,` ç­‰
    url = f"data:image/png;base64,{b64}"
    return HumanMessage(
        content=[
            {"type": "text", "text": "è¿™æ˜¯å½“åœ°çš„å«æ˜Ÿå›¾ï¼Œè¯·æ®æ­¤åˆ†æå±±ä½“ã€æ°´ä½“ã€åœ°å½¢ç­‰ä¿¡æ¯ã€‚"},
            {"type": "image_url", "image_url": {"url": url}}
        ]
    )

# -------------------------------------------------
# 3. ä»£ç†æç¤ºæ¨¡æ¿
# -------------------------------------------------

# å°é£åˆ†æä»£ç†ï¼ˆä¸»è„‘ï¼‰
analysis_prompt = ChatPromptTemplate.from_messages([
    ("system",
     "ä½ æ˜¯å°é£ç¾å®³é¢„è­¦åˆ†æä¸“å®¶ã€‚ä½ çš„å·¥ä½œæ˜¯ï¼š\n"
     "å…ˆæ ¹æ®ç”¨æˆ·è¾“å…¥çš„ç»çº¬åº¦ï¼ŒåŠ¡å¿…åŠ¡å¿…å…ˆè°ƒç”¨ typhoon_api èŠ‚ç‚¹è·å–ä¿¡æ¯ï¼Œè¯·åŠ¡å¿…ç”Ÿæˆtool_callï¼Œç„¶åä¸€å®šè¦ä¼ å…¥ä¸¤ä¸ªå‚æ•°ï¼šlatï¼ˆçº¬åº¦ï¼‰ã€lonï¼ˆç»åº¦ï¼‰ï¼Œå‡ä¿ç•™ä¸€ä½å°æ•°ã€‚\n"
     "ç„¶åå†é€šè¿‡routerè·¯ç”±ï¼Œå‘floodèŠ‚ç‚¹çš„åœ°å½¢-æ°´ä½“ä¸“å®¶æ™ºèƒ½ä½“ç´¢è¦åœ°å½¢ã€æ°´ä½“ç­‰ä¿¡æ¯ï¼Œå…ˆä¸è¦æ€¥ç€è¾“å‡ºæ–¹æ¡ˆã€‚è®°ä½ï¼Œè¿™ä¸ªfloodåœ°å½¢æ°´ä½“ä¸“å®¶ä¹Ÿæ˜¯ä¸€ä¸ªæ™ºèƒ½ä½“ï¼Œä»–ä¸ä¼šå¸®ä½ ç”Ÿæˆæ–¹æ¡ˆï¼Œæˆ‘å·²ç»æå‰ç»™äº†ä»–å½“åœ°å«æ˜Ÿå›¾ï¼Œä»–åªä¼šæ ¹æ®å«æ˜Ÿå›¾å»åˆ†æå½“åœ°çš„æ°´ä½“ã€å±±ä½“åˆ†å¸ƒç­‰ä¿¡æ¯ã€‚ä½ è¦å…ˆé—®è¿™ä¸ªä¸“å®¶ç®€å•çš„é—®é¢˜ï¼Œå»è¾“å‡ºé—®é¢˜é—®ä»–ï¼Œæ¯”å¦‚è¯´é—®ä»–:ä¸“å®¶æ‚¨å¥½ï¼Œè¯·é—®è¿™ä¸ªåœ°æ–¹æ°´ä½“çš„åˆ†å¸ƒæ˜¯æ€ä¹ˆæ ·çš„ï¼Ÿä½ å¯ä»¥å’Œä»–è¿›è¡Œå¤šè½®å¯¹è¯ï¼Œä¸æ–­è¯¢é—®ä¸€äº›å±±ä½“ï¼Œæ°´ä½“çš„ç»†èŠ‚\n"
     "æ”¶é›†è¶³å¤Ÿä¿¡æ¯åæˆ–è€…å·²ç»æ˜¯è¿›è¡Œäº†å…­è½®å¯¹è¯åï¼Œè¦å¯¹ä¸“å®¶æ™ºèƒ½ä½“è¯´â€œå¤Ÿäº†â€ï¼Œç„¶ååœæ­¢ä¸ä¸“å®¶æ™ºèƒ½ä½“èŠ‚ç‚¹çš„å¯¹è¯ã€‚è®°ä½ï¼Œè¶…è¿‡å…­è½®å¯¹è¯ä¹Ÿè¦å¼ºåˆ¶åœæ­¢å¯¹è¯ï¼Œç„¶åè¾“å‡ºç»™ç”¨æˆ·ï¼Œè¦æ ¹æ®å¾—åˆ°çš„ä¿¡æ¯å‘ç”¨æˆ·è¾“å‡ºå®Œæ•´é£é™©è¯„ä¼°ã€é¢„é˜²æ–¹æ¡ˆã€ç–æ•£å»ºè®®ã€ç‰©èµ„æ¸…å•ã€‚\n"
     "å¦‚æœä½ æˆåŠŸæ¥æ”¶åˆ°æ¥è‡ªä¸“å®¶æ¨¡å‹çš„ä¿¡æ¯ï¼Œè¯·ä½ å…ˆè¯´ï¼šâ€œæˆ‘æ¥æ”¶åˆ°ä¿¡æ¯äº†â€,å¦åˆ™å…ˆè¯´â€œæˆ‘æ²¡æœ‰æ¥æ”¶åˆ°ä¸“å®¶çš„ä¿¡æ¯â€\n"
     "ä½ åƒä¸‡è¦åˆ†æ¸…ä½ åœ¨å’Œè°è¯´è¯ï¼Œè·Ÿä¸“å®¶æ™ºèƒ½ä½“å¯¹è¯çš„æ—¶å€™ä½ åªè¦è¾“å‡ºé—®é¢˜å°±å¥½äº†ï¼Œä¸è¦åˆ†æï¼Œä¸è¦åƒå’Œç”¨æˆ·è¯´è¯ä¸€æ ·ï¼Œä½ è¦è®°ä½ä½ æ˜¯åœ¨å‘ä¸“å®¶æ™ºèƒ½ä½“é—®é—®é¢˜ï¼Œæœ€åè¾“å‡ºç»™ç”¨æˆ·äº†å†æ¥åˆ†ææ–¹æ¡ˆ"
     "è‹¥æ•°æ®å·²å……è¶³ï¼Œåœ¨æœ€åä¸€æ¡æ¶ˆæ¯ä¸­æ˜¾å¼åŒ…å« **FINAL ANSWER** å­—æ ·ç»“æŸæµç¨‹ã€‚\n"
     "å¦‚æœä½ ç»§ç»­è°ƒç”¨ä¸“å®¶æ™ºèƒ½ä½“ï¼Œå´æ²¡æœ‰é—®ä»–é—®é¢˜ï¼Œä»–ä¼šæé†’ä½ ä¸è¦å†å’Œä»–å¯¹è¯äº†ï¼Œè¿™æ—¶å€™è¯·ä½ ç»“æŸå’Œä¸“å®¶æ™ºèƒ½ä½“çš„å¯¹è¯ï¼ŒæŠŠæ–¹æ¡ˆè¾“å‡ºç»™ç”¨æˆ·ç„¶åç»“æŸæµç¨‹"),
    MessagesPlaceholder(variable_name="messages")
])
analysis_agent = analysis_prompt | llm.bind_tools([typhoon_api])

# åœ°å½¢-æ°´ä½“ä¸“å®¶ï¼ˆä»…åšé—®ç­”ï¼Œä¸è°ƒç”¨å·¥å…·ï¼‰
flood_prompt = ChatPromptTemplate.from_messages([
    ("system",
     "ä½ æ˜¯åœ°å½¢-æ°´ä½“æ•°æ®ä¸“å®¶ã€‚å½“å°é£åˆ†ææ™ºèƒ½ä½“å‘ä½ è¯¢é—®æŸåœ°çš„åœ°å½¢ã€å±±ä½“ã€æ°´ä½“ç­‰ä¿¡æ¯æ—¶ï¼Œ\n"
     "å¦‚æœä½ æ¥æ”¶åˆ°äº†æ¥è‡ªåˆ†ææ™ºèƒ½ä½“çš„é—®é¢˜è€Œä¸æ˜¯ç”¨æˆ·çš„è¾“å…¥ï¼Œè¯·å…ˆè¯´ï¼šâ€œæˆ‘å·²æ”¶åˆ°é—®é¢˜ï¼Œåˆ†ææ™ºèƒ½ä½“æ‚¨å¥½ï¼â€ç„¶ååŸºäºçŸ¥è¯†åº“ï¼Œåˆ†æé‚£å¼ å«æ˜Ÿå›¾ï¼Œç»™å‡ºå°½å¯èƒ½è¯¦ç»†çš„ã€å«æ˜Ÿå›¾ä¸Šé¢çš„æ°´ä½“ã€å±±ä½“æ•°æ®å°±å¥½äº†ï¼Œä¸ç”¨ç»™å»ºè®®ä»€ä¹ˆçš„ï¼Œç„¶åè¿”å›ç»™åˆ†ææ™ºèƒ½ä½“ï¼Œå¦‚æœåˆ†ææ™ºèƒ½ä½“ç»§ç»­é—®ï¼Œä½ å°±ç»§ç»­å›ç­”ä»–çš„é—®é¢˜ï¼Œç›´åˆ°å¯¹æ–¹è¯´â€œå¤Ÿäº†â€ã€‚\n"
     "å¦‚æœåˆ†ææ™ºèƒ½ä½“åœ¨å’Œä½ å¯¹è¯ï¼Œå´æ²¡æœ‰æå‡ºé—®é¢˜ï¼Œè¯·ä½ æé†’ä¸€ä¸‹ä»–ï¼šä½ è¯¥è¾“å‡ºæ–¹æ¡ˆç»™ç”¨æˆ·äº†ï¼Œæ²¡æœ‰é—®é¢˜è¯·ä¸è¦ç»§ç»­å’Œæˆ‘å¯¹è¯"),
    MessagesPlaceholder(variable_name="messages")
])
flood_agent = flood_prompt | Expert_llm



def _extract_last_question(messages: Sequence[BaseMessage]) -> Sequence[BaseMessage]:
    """
    åªä¿ç•™ï¼š
    1. æœ€åä¸€æ¡ HumanMessageï¼ˆç”¨æˆ·é—®é¢˜ï¼‰
    2. ç´§æ¥åœ¨å®ƒåé¢çš„ AIMessageï¼ˆåˆ†æå¸ˆè¿½é—®ï¼Œå¦‚æœæœ‰ï¼‰
    3. å…¶ä½™å…¨éƒ¨ä¸¢å¼ƒ
    è¿™æ ·å¯ä»¥æœ€å¤§é™åº¦å‡å°‘ token
    """
    # å€’åºæ‰¾ HumanMessage
    for i in range(len(messages) - 1, -1, -1):
        if isinstance(messages[i], HumanMessage):
            # å¦‚æœåé¢è¿˜æœ‰ä¸€æ¡ AIMessageï¼Œä¹Ÿå¸¦ä¸Šï¼ˆé€šå¸¸å°±æ˜¯è¿½é—®ï¼‰
            if i + 1 < len(messages) and isinstance(messages[i + 1], AIMessage):
                return [messages[i], messages[i + 1]]
            return [messages[i]]
    # fallbackï¼šå®åœ¨æ²¡æœ‰ HumanMessageï¼Œç»™ç©º
    return [HumanMessage(content="è¯·åŸºäºå«æ˜Ÿå›¾æè¿°å½“åœ°åœ°å½¢ã€æ°´ä½“ç‰¹å¾ã€‚")]


# -------------------------------------------------
# 4. èŠ‚ç‚¹å‡½æ•°
# -------------------------------------------------

# ---------- analysis_node ----------
def analysis_node(state: TyphoonAlertState):
    raw = analysis_agent.invoke(state)
    if isinstance(raw, AIMessage):
        msg = raw
    else:
        msg = AIMessage(content=str(raw))
    msg.name = "analyst"          # æ–°å¢
    print(f"[DEBUG] analysis_node ç”Ÿæˆçš„æ¶ˆæ¯ï¼š{msg.content}")  # æ‰“å°ç”Ÿæˆçš„æ¶ˆæ¯
    return {"messages": [msg], "sender": "analyst"}

# ---------- flood_node ----------
def flood_node(state: TyphoonAlertState):
    #  åªå–å…³é”®é—®é¢˜
    concise_msgs = _extract_last_question(state["messages"])
    print("â†“â†“â†“â†“  flood_node æ”¶åˆ°çš„æ¶ˆæ¯  â†“â†“â†“â†“")
    for m in concise_msgs:
        print(f"[{type(m).__name__}] {m.content}")
    print("â†‘â†‘â†‘â†‘  ä»¥ä¸Šä¸º flood_node æ”¶åˆ°çš„æ¶ˆæ¯  â†‘â†‘â†‘â†‘")

    # åªåœ¨ç¬¬ä¸€æ¬¡è¿›å…¥ flood_node æ—¶æŠŠå›¾ç‰‡å¡è¿›å»
    image_msg = _make_image_message(state["image"])
    temp_messages = concise_msgs + [image_msg]

    raw = flood_agent.invoke({"messages": temp_messages})
    if isinstance(raw, AIMessage):
        msg = raw
    else:
        msg = AIMessage(content=str(raw))
    msg.name = "flood"            # æ–°å¢
    print(f"[DEBUG] flood_node è¿”å›ï¼š{msg.content}")  # æ‰“å°è¿”å›å€¼
    return {"messages": [msg], "sender": "flood"}

# -------------------------------------------------
# 5. æ¡ä»¶è·¯ç”±å‡½æ•°
# -------------------------------------------------
def router(state: TyphoonAlertState) -> Literal["tool_node", "flood", "__end__", "continue"]:
    last_msg = state["messages"][-1]

    if isinstance(last_msg, AIMessage) and last_msg.tool_calls:
        next_node = "tool_node"
    elif "FINAL ANSWER" in str(last_msg.content):
        next_node = "__end__"
    else:
        sender = state.get("sender", "analyst")
        if sender == "analyst":
            next_node = "flood"
        elif sender == "flood":
            next_node = "analyst"
        else:
            next_node = "continue"

    # ğŸ‘‡ åŠ è¿™ 1 è¡Œ
    print("[ROUTER]", state.get("sender"), "â†’", next_node)
    return next_node

# -------------------------------------------------
# 6. æ„å»ºå›¾
# -------------------------------------------------
workflow = StateGraph(TyphoonAlertState)

workflow.add_node("analyst", analysis_node)
workflow.add_node("flood", flood_node)
workflow.add_node("tool_node", tool_node)

# START -> analyst
workflow.add_edge(START, "analyst")

# analyst çš„æ¡ä»¶è¾¹
workflow.add_conditional_edges(
    "analyst",
    router,
    {
        "tool_node": "tool_node",
        "flood": "flood",
        "__end__": END,
        "continue": "analyst"  # ç†è®ºä¸Šä¸ä¼šèµ°åˆ°è¿™é‡Œ
    }
)

# flood çš„æ¡ä»¶è¾¹
workflow.add_conditional_edges(
    "flood",
    router,
    {
        "analyst": "analyst",
        "__end__": END,
        "continue": "flood"
    }
)

# tool_node çš„è¿”å›è¾¹ï¼šå§‹ç»ˆå›åˆ°è°ƒç”¨å®ƒçš„èŠ‚ç‚¹
workflow.add_edge("tool_node", "analyst")


new_warning = workflow.compile(name="new_warning")


# 7. è¿è¡Œå…¥å£ï¼ˆæ”¹ä¸º async + ä½¿ç”¨æ£€æŸ¥ç‚¹ï¼‰
# ----------------------------------------------------------
async def run_typhoon_alert(location: str, satellite_image: bytes, thread_id: str = "thread-typhoon-1"):
    """å¼‚æ­¥è¿è¡Œå°é£é¢„è­¦ç³»ç»Ÿï¼Œå¸¦æ£€æŸ¥ç‚¹æŒä¹…åŒ–"""
    initial = {
        "messages": [HumanMessage(content=location)],
        "sender": "analyst",
        "image": satellite_image
    }
# ä½¿ç”¨ AsyncSqliteSaverï¼Œæ•°æ®åº“æ–‡ä»¶ checkpoints.db ä¼šè‡ªåŠ¨åˆ›å»º
    async with AsyncSqliteSaver.from_conn_string("checkpoints.db") as memory:
        graph = workflow.compile(checkpointer=memory)
        try:
            graph.get_graph().draw_mermaid_png(output_file_path="./new_warning.png")
        except Exception:
            # This requires some extra dependencies and is optional
            pass
        print(f"[DEBUG] å¼€å§‹ thread={thread_id}")
        final_state = await graph.ainvoke(
            initial,
            {"configurable": {"thread_id": thread_id}}
        )
        print(f"[DEBUG] ç»“æŸï¼Œå…± {len(final_state['messages'])} æ¡æ¶ˆæ¯")
        # å–å‡ºæœ€åä¸€æ¡æ¥è‡ª analyst çš„æ¶ˆæ¯
        for msg in reversed(final_state["messages"]):
            if isinstance(msg, AIMessage) and msg.name == "analyst":
                return msg.content
        return "æœªç”Ÿæˆæœ‰æ•ˆé¢„è­¦æ–¹æ¡ˆ"

# ----------------------------------------------------------
# 8. ç¤ºä¾‹è¿è¡Œï¼ˆasync mainï¼‰
# ----------------------------------------------------------
async def main():
    location_name = "å¹¿ä¸œçœæ¢…å·å¸‚"
    lat, lon = 24.3, 116.1
    location = f"{location_name}ï¼ˆçº¬åº¦ {lat:.1f}ï¼Œç»åº¦ {lon:.1f}ï¼‰"

    # è¯»ä¸€å¼ æœ¬åœ°å«æ˜Ÿå›¾åšæ¼”ç¤º
    with open("demo_picture.png", "rb") as f:
        img_bytes = f.read()
    print(f"æ­£åœ¨ä¸º {location} ç”Ÿæˆå°é£é¢„è­¦æ–¹æ¡ˆ...\n")
    result = await run_typhoon_alert(location, img_bytes)
    print("ç”Ÿæˆçš„é¢„è­¦æ–¹æ¡ˆï¼š\n")
    print(result)

if __name__ == "__main__":
    asyncio.run(main())